### 高并发,大流量
1. 背景
1. 常用概念
1. 一般网站的QPS情况
1. 解决方案
1. 实践分享

#### 一. 背景
> 对于我们所研发的网站，若网站的访问量非常大，那么我们必须考虑相关的并发访问问题，
> 而并发问题是绝大部分的程序员头疼的问题。

#### 二. 常用概念
1. QPS: 每秒查询率（Query Per Second），每秒的响应请求数，也即是最大吞吐能力
    >+ 峰值QPS: 每天 80% 的访问集中在 20 % 的时间里，这 20 % 时间叫做峰值时间
    >+ 单台服务器每天 PV 计算： 每天总 PV = QPS * 3600 * 6
    >+ 服务器数量 : ceil（每天总 PV / 单台服务器每天总 PV)
1. PV: page view 的缩写，即页面浏览量，或点击量
1. UV: 独立访客即 Unique Visitor，访问您网站的一台电脑客户端为一个访客
1. PR: 即PageRank，网页的级别技术。级别从1到10级，10 级为满分。PR 值越高说明该
    网页越受欢迎（越重要）
1. QPS 不等于并发连接数

#### 一般网站的QPS情况
1. 平均值 < 50QPS
    > 小型网站，一般的服务器就可以应付，可以用最简单的方法快速搭建，短期没有太多的技术瓶颈，  
     只要服务器稳定即可，网络通畅即可
1. 50QPS < 平均值 < 100QPS
   > DB 数据库极限型:常用的关系型数据库的每次请求大多都能控制在 0.01 秒左右，  
   > 就算你研发的 Web 网站每页面只有一次数据库请求，那么页面请求无法保证在 1 秒钟内完成 100 个请求，  
   > 这个阶段要考虑做 Cache 或者多 DB 负载
1. 300QPS<平均值<800QPS
   >带宽极限型
   >
   >服务器常用 IDC 提供的“百兆带宽”，这意味着网站出口的实际带宽是 8 M Byte左右。假定每个页面只有 10 K Byte，在这个并发条件下，百兆带宽已经快速的占用资源完毕。
   >
   >这要就可能考虑优化的技术如同：CDN 加速 & 异地缓存，集群负载等技术   
1. 500QPS < 平均值 < 1000QPS
   > 内网带宽极限＋缓存极限型
   >
   > 由于 Key/value 的特性，每个页面对缓存技术的请求远大于直接对 DB 的请求 
1. 1000QPS < 平均值 < 2000QPS
   > FORK / SELECT，锁模式极限型
   >
   > 线程模型决定吞吐量。不管你系统中最常见的锁是什么锁，这个级别下，文件系统访问锁都成为了灾难。
   > 这就要求系统中不能存在中央节点，所有的数据都必须分布存储，数据需要分布处理。总之， 分布 
1. 2000 QPS < 平均值
   > C10K 极限 现在阿里的技术以及实现了 C25K，但熟悉 java 的短板理论，
   木桶原理很明显我们能得出， 网站整体并发的永远是最慢的那个。  
   > 在阿里巴巴的双 11 的晚上 24 点的时候，肯定超过这个值     

#### 三. 解决方案
1. 数据库
1. 缓存
1. web负载均衡
     